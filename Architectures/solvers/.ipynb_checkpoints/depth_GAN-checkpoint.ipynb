{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/riccardo/Desktop/OcclusionInference/Architectures')\n",
    "from data_loaders.dataset_unsup import MyDataset_unsup\n",
    "\n",
    "\n",
    "# Set random seem for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root directory for dataset\n",
    "dataroot = \"/home/riccardo/Desktop/Data/better_100k_bw_ro/digts/\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 8\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 32\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 50\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0005\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting train image files\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = \"{}train/orig/\".format(dataroot)\n",
    "train_target_paths = \"{}train/inverse/\".format(dataroot)\n",
    "train_data_size = len(os.listdir(train_image_paths))\n",
    "train_data = MyDataset_unsup(train_image_paths, train_target_paths, image_size, 'train', train_data_size)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7afc278cc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))['x']\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch.to(device)[:32], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(50, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(nc, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (9): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/10][0/1563]\tLoss_D: 1.6950\tLoss_G: 3.7230\tD(x): 0.4562\tD(G(z)): 0.5244 / 0.0291\n",
      "[0/10][50/1563]\tLoss_D: 0.2895\tLoss_G: 8.1485\tD(x): 0.9108\tD(G(z)): 0.1708 / 0.0004\n",
      "[0/10][100/1563]\tLoss_D: 0.8420\tLoss_G: 3.2902\tD(x): 0.7074\tD(G(z)): 0.3139 / 0.0476\n",
      "[0/10][150/1563]\tLoss_D: 0.6389\tLoss_G: 2.0346\tD(x): 0.6652\tD(G(z)): 0.1521 / 0.1679\n",
      "[0/10][200/1563]\tLoss_D: 0.6632\tLoss_G: 2.7183\tD(x): 0.7394\tD(G(z)): 0.2686 / 0.0834\n",
      "[0/10][250/1563]\tLoss_D: 0.4606\tLoss_G: 2.1706\tD(x): 0.7411\tD(G(z)): 0.1261 / 0.1508\n",
      "[0/10][300/1563]\tLoss_D: 0.4626\tLoss_G: 2.1111\tD(x): 0.7404\tD(G(z)): 0.1217 / 0.1549\n",
      "[0/10][350/1563]\tLoss_D: 0.4559\tLoss_G: 2.6262\tD(x): 0.8234\tD(G(z)): 0.2068 / 0.0914\n",
      "[0/10][400/1563]\tLoss_D: 0.4464\tLoss_G: 2.0496\tD(x): 0.7234\tD(G(z)): 0.0823 / 0.1683\n",
      "[0/10][450/1563]\tLoss_D: 0.9945\tLoss_G: 2.9205\tD(x): 0.8767\tD(G(z)): 0.4974 / 0.0789\n",
      "[0/10][500/1563]\tLoss_D: 0.2546\tLoss_G: 4.3241\tD(x): 0.9570\tD(G(z)): 0.1795 / 0.0183\n",
      "[0/10][550/1563]\tLoss_D: 0.0730\tLoss_G: 4.0905\tD(x): 0.9526\tD(G(z)): 0.0232 / 0.0219\n",
      "[0/10][600/1563]\tLoss_D: 0.2069\tLoss_G: 2.8548\tD(x): 0.8948\tD(G(z)): 0.0826 / 0.0783\n",
      "[0/10][650/1563]\tLoss_D: 0.1294\tLoss_G: 3.4797\tD(x): 0.9384\tD(G(z)): 0.0609 / 0.0374\n",
      "[0/10][700/1563]\tLoss_D: 0.0861\tLoss_G: 4.4951\tD(x): 0.9716\tD(G(z)): 0.0535 / 0.0150\n",
      "[0/10][750/1563]\tLoss_D: 0.1424\tLoss_G: 3.4889\tD(x): 0.9160\tD(G(z)): 0.0486 / 0.0412\n",
      "[0/10][800/1563]\tLoss_D: 0.1139\tLoss_G: 2.5221\tD(x): 0.9071\tD(G(z)): 0.0122 / 0.1099\n",
      "[0/10][850/1563]\tLoss_D: 0.4696\tLoss_G: 2.5246\tD(x): 0.8334\tD(G(z)): 0.2274 / 0.1058\n",
      "[0/10][900/1563]\tLoss_D: 0.3219\tLoss_G: 5.0329\tD(x): 0.9446\tD(G(z)): 0.2050 / 0.0121\n",
      "[0/10][950/1563]\tLoss_D: 0.1019\tLoss_G: 4.5478\tD(x): 0.9695\tD(G(z)): 0.0661 / 0.0152\n",
      "[0/10][1000/1563]\tLoss_D: 0.1955\tLoss_G: 0.6205\tD(x): 0.8443\tD(G(z)): 0.0137 / 0.5920\n",
      "[0/10][1050/1563]\tLoss_D: 0.4467\tLoss_G: 2.4442\tD(x): 0.7361\tD(G(z)): 0.0528 / 0.1091\n",
      "[0/10][1100/1563]\tLoss_D: 0.1455\tLoss_G: 3.6387\tD(x): 0.9154\tD(G(z)): 0.0489 / 0.0380\n",
      "[0/10][1150/1563]\tLoss_D: 0.0577\tLoss_G: 3.8916\tD(x): 0.9680\tD(G(z)): 0.0239 / 0.0277\n",
      "[0/10][1200/1563]\tLoss_D: 0.5749\tLoss_G: 2.8718\tD(x): 0.7757\tD(G(z)): 0.2332 / 0.0768\n",
      "[0/10][1250/1563]\tLoss_D: 0.1171\tLoss_G: 3.7778\tD(x): 0.9214\tD(G(z)): 0.0298 / 0.0319\n",
      "[0/10][1300/1563]\tLoss_D: 0.0762\tLoss_G: 5.5051\tD(x): 0.9874\tD(G(z)): 0.0599 / 0.0058\n",
      "[0/10][1350/1563]\tLoss_D: 0.4840\tLoss_G: 1.9624\tD(x): 0.7610\tD(G(z)): 0.1718 / 0.1669\n",
      "[0/10][1400/1563]\tLoss_D: 0.2183\tLoss_G: 4.0608\tD(x): 0.9280\tD(G(z)): 0.1280 / 0.0219\n",
      "[0/10][1450/1563]\tLoss_D: 0.0806\tLoss_G: 3.9363\tD(x): 0.9686\tD(G(z)): 0.0463 / 0.0266\n",
      "[0/10][1500/1563]\tLoss_D: 0.0533\tLoss_G: 4.7878\tD(x): 0.9762\tD(G(z)): 0.0280 / 0.0125\n",
      "[0/10][1550/1563]\tLoss_D: 0.0315\tLoss_G: 5.4508\tD(x): 0.9798\tD(G(z)): 0.0107 / 0.0063\n",
      "[1/10][0/1563]\tLoss_D: 0.7969\tLoss_G: 15.5487\tD(x): 0.9991\tD(G(z)): 0.4862 / 0.0000\n",
      "[1/10][50/1563]\tLoss_D: 0.0781\tLoss_G: 4.0280\tD(x): 0.9821\tD(G(z)): 0.0575 / 0.0227\n",
      "[1/10][100/1563]\tLoss_D: 0.2611\tLoss_G: 3.2164\tD(x): 0.8769\tD(G(z)): 0.1087 / 0.0547\n",
      "[1/10][150/1563]\tLoss_D: 0.1219\tLoss_G: 3.6024\tD(x): 0.9606\tD(G(z)): 0.0754 / 0.0350\n",
      "[1/10][200/1563]\tLoss_D: 0.0685\tLoss_G: 4.1203\tD(x): 0.9440\tD(G(z)): 0.0095 / 0.0215\n",
      "[1/10][250/1563]\tLoss_D: 0.0529\tLoss_G: 4.7092\tD(x): 0.9881\tD(G(z)): 0.0392 / 0.0124\n",
      "[1/10][300/1563]\tLoss_D: 0.6271\tLoss_G: 1.6668\tD(x): 0.6789\tD(G(z)): 0.1718 / 0.2347\n",
      "[1/10][350/1563]\tLoss_D: 0.1622\tLoss_G: 4.0791\tD(x): 0.9720\tD(G(z)): 0.1201 / 0.0232\n",
      "[1/10][400/1563]\tLoss_D: 0.1490\tLoss_G: 4.0904\tD(x): 0.9561\tD(G(z)): 0.0947 / 0.0224\n",
      "[1/10][450/1563]\tLoss_D: 0.1941\tLoss_G: 3.5869\tD(x): 0.9076\tD(G(z)): 0.0859 / 0.0367\n",
      "[1/10][500/1563]\tLoss_D: 0.0629\tLoss_G: 4.3426\tD(x): 0.9763\tD(G(z)): 0.0372 / 0.0165\n",
      "[1/10][550/1563]\tLoss_D: 0.0387\tLoss_G: 4.6163\tD(x): 0.9841\tD(G(z)): 0.0216 / 0.0140\n",
      "[1/10][600/1563]\tLoss_D: 0.0265\tLoss_G: 5.0553\tD(x): 0.9886\tD(G(z)): 0.0147 / 0.0098\n",
      "[1/10][650/1563]\tLoss_D: 0.0215\tLoss_G: 5.2412\tD(x): 0.9873\tD(G(z)): 0.0086 / 0.0073\n",
      "[1/10][700/1563]\tLoss_D: 0.0194\tLoss_G: 4.9932\tD(x): 0.9964\tD(G(z)): 0.0156 / 0.0095\n",
      "[1/10][750/1563]\tLoss_D: 0.8349\tLoss_G: 1.1944\tD(x): 0.5576\tD(G(z)): 0.1716 / 0.3447\n",
      "[1/10][800/1563]\tLoss_D: 0.8138\tLoss_G: 4.9292\tD(x): 0.9673\tD(G(z)): 0.4886 / 0.0104\n",
      "[1/10][850/1563]\tLoss_D: 0.1362\tLoss_G: 2.9404\tD(x): 0.8998\tD(G(z)): 0.0236 / 0.0724\n",
      "[1/10][900/1563]\tLoss_D: 0.1111\tLoss_G: 3.4982\tD(x): 0.9420\tD(G(z)): 0.0465 / 0.0375\n",
      "[1/10][950/1563]\tLoss_D: 0.3593\tLoss_G: 3.2558\tD(x): 0.8406\tD(G(z)): 0.1437 / 0.0558\n",
      "[1/10][1000/1563]\tLoss_D: 0.0803\tLoss_G: 3.1832\tD(x): 0.9398\tD(G(z)): 0.0170 / 0.0583\n",
      "[1/10][1050/1563]\tLoss_D: 0.4420\tLoss_G: 2.1143\tD(x): 0.7443\tD(G(z)): 0.0979 / 0.1812\n",
      "[1/10][1100/1563]\tLoss_D: 0.0572\tLoss_G: 4.6005\tD(x): 0.9722\tD(G(z)): 0.0277 / 0.0153\n",
      "[1/10][1150/1563]\tLoss_D: 0.0422\tLoss_G: 4.3030\tD(x): 0.9708\tD(G(z)): 0.0122 / 0.0185\n",
      "[1/10][1200/1563]\tLoss_D: 0.0226\tLoss_G: 5.2894\tD(x): 0.9907\tD(G(z)): 0.0130 / 0.0090\n",
      "[1/10][1250/1563]\tLoss_D: 0.0214\tLoss_G: 4.9385\tD(x): 0.9874\tD(G(z)): 0.0085 / 0.0109\n",
      "[1/10][1300/1563]\tLoss_D: 1.3339\tLoss_G: 4.1749\tD(x): 0.9635\tD(G(z)): 0.6667 / 0.0217\n",
      "[1/10][1350/1563]\tLoss_D: 0.4097\tLoss_G: 3.7719\tD(x): 0.9635\tD(G(z)): 0.2835 / 0.0327\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        \n",
    "        real_cpu = data['x'].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch['x'].to(device)[:32], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
