{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"//home/riccardo/Desktop/Experiments/encoder_sup/3_digts/arch/B_matched/data_last.p\"\n",
    "output_dir = \"/home/riccardo/Desktop/Experiments/encoder_sup/3_digts/arch/B_matched\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load( open( filename, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gnrl_last_iter_loss'] = [x.item() for x in data['gnrl_last_iter_loss']]\n",
    "data['gnrl_back_loss'] = [x.item() for x in data['gnrl_back_loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Number of trainable parameters: {}, \\nFinal training loss: {:.3f}, Final gnrl loss: {:.3f}, \\n Last recurrent iter loss: train {:.3f}, gnrl {:.3f}'.format(\n",
    "                   308225, \n",
    "                np.mean(data['train_loss'][-5:]),\n",
    "                np.mean(data['gnrl_loss'][-5:]),  \n",
    "                np.mean(data['train_last_iter_loss'][-5:]),\n",
    "                np.mean(data['gnrl_last_iter_loss'][-5:] ) ), \n",
    "                fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['train_loss'], 'coral', linewidth=2.5, label = \"train loss\")\n",
    "plt.plot(data['iter'], data['gnrl_loss'], 'dodgerblue', linewidth=2, label = \"gnrl  loss\")\n",
    "plt.plot(data['iter'], data['train_last_iter_loss'], 'r', linewidth=2, label = \"train last iter loss\")\n",
    "plt.plot(data['iter'], data['gnrl_last_iter_loss'], 'seagreen', linewidth=2, label = \"gnrl last iter loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Train_Gnrl_loss_Curves.png'.format(output_dir))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Number of trainable parameters: {}, \\n Final train accuracy: back: {:.2f}, mid:{:.2f}, front:{:.2f} '.format(\n",
    "                   308225, np.mean(data['train_back_accuracy'][-5:]),\n",
    "                   np.mean(data['train_mid_accuracy'][-5:]), np.mean(data['train_front_accuracy'][-5:])),\n",
    "                   fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['train_back_accuracy'], 'coral', linewidth=2.5, label = \"back digit accuracy\")\n",
    "plt.plot(data['iter'], data['train_mid_accuracy'], 'seagreen', linewidth=2.5, label = \"mid digit accuracy\")\n",
    "plt.plot(data['iter'], data['train_front_accuracy'], 'dodgerblue', linewidth=2.5, label = \"front digit accuracy\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Train_accuracy_Curves.png'.format(output_dir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Number of trainable parameters: {}, \\n Final gnrl accuracy: back: {:.2f}, mid:{:.2f}, front:{:.2f} '.format(\n",
    "                   308225, np.mean(data['gnrl_back_accuracy'][-5:]),\n",
    "                   np.mean(data['gnrl_mid_accuracy'][-5:]), np.mean(data['gnrl_front_accuracy'][-5:])),\n",
    "                   fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['gnrl_back_accuracy'], 'coral', linewidth=2.5, label = \"back digit accuracy\")\n",
    "plt.plot(data['iter'], data['gnrl_mid_accuracy'], 'seagreen', linewidth=2.5, label = \"mid digit accuracy\")\n",
    "plt.plot(data['iter'], data['gnrl_front_accuracy'], 'dodgerblue', linewidth=2.5, label = \"front digit accuracy\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Gnrl_accuracy_Curves.png'.format(output_dir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Number of trainable parameters: {}, \\n Final train Losses: back: {:.2f}, mid:{:.2f}, front:{:.2f}, xy:{:.2f} '.format(\n",
    "                   308225, np.mean(data['train_back_loss'][-5:]),\n",
    "                   np.mean(data['train_mid_loss'][-5:]), np.mean(data['train_front_loss'][-5:]) , \n",
    "                    np.mean(data['train_xy_loss'][-5]) ), fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['train_back_loss'], 'coral', linewidth=2.5, label = \"back digit loss\")\n",
    "plt.plot(data['iter'], data['train_mid_loss'], 'seagreen', linewidth=2.5, label = \"mid digit loss\")\n",
    "plt.plot(data['iter'], data['train_front_loss'], 'dodgerblue', linewidth=2.5, label = \"front digit loss\")\n",
    "plt.plot(data['iter'], data['train_xy_loss'], 'r', linewidth=2.5, label = \"location loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Train_loss_Curves.png'.format(output_dir))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-21a9adb2095a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig_lc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fig_lc.suptitle('Number of trainable parameters: {}, \\n Final Gnrl Losses: back: {:.2f}, mid:{:.2f}, front:{:.2f}, xy:{:.2f} '.format(\n\u001b[0;32m----> 3\u001b[0;31m                    \u001b[0;36m308225\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gnrl_back_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gnrl_mid_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gnrl_front_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     np.mean(data['gnrl_xy_loss'][-5]) ), fontsize=14)\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.dtype' object has no attribute 'type'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Number of trainable parameters: {}, \\n Final Gnrl Losses: back: {:.2f}, mid:{:.2f}, front:{:.2f}, xy:{:.2f} '.format(\n",
    "                   308225, np.mean(data['gnrl_back_loss'][-5:]),\n",
    "                   np.mean(data['gnrl_mid_loss'][-5:]), np.mean(data['gnrl_front_loss'][-5:]) , \n",
    "                    np.mean(data['gnrl_xy_loss'][-5]) ), fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['gnrl_back_loss'], 'coral', linewidth=2.5, label = \"back digit loss\")\n",
    "plt.plot(data['iter'], data['gnrl_mid_loss'], 'seagreen', linewidth=2.5, label = \"mid digit loss\")\n",
    "plt.plot(data['iter'], data['gnrl_front_loss'], 'dodgerblue', linewidth=2.5, label = \"front digit loss\")\n",
    "plt.plot(data['iter'], data['gnrl_xy_loss'], 'r', linewidth=2.5, label = \"location loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Gnrl_loss_Curves.png'.format(output_dir))\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train_recon_loss'] = [x.item() for x in data['train_recon_loss'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Learning curves \\nNumber of trainable parameters: {}, \\nFinal training loss: {:.3f} , Final gnrl loss: {:.3f} '.format(\n",
    "                   240193, np.mean(data['train_recon_loss'][-5:]),\n",
    "                 np.mean(data['gnrl_recon_loss'][-5:])), fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], data['train_recon_loss'], 'coral', linewidth=2.5, label = \"train reconstruction loss\")\n",
    "plt.plot(data['iter'], data['gnrl_recon_loss'], 'dodgerblue', linewidth=2, label = \"gnrl reconstruction loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Train_Gnrl_loss_Curves.png'.format(output_dir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [y.item() for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.539185714721679"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_filename ='/home/riccardo/Desktop/Experiments/decoder_sup/3_digts/arch/BL/LOGBOOK.txt'\n",
    "f=open(txt_filename)\n",
    "lines=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ', 4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-6fae687716a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m161\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ', 4'"
     ]
    }
   ],
   "source": [
    "loss_1 = []\n",
    "loss_2 = []\n",
    "loss_3 = []\n",
    "loss_4 = []\n",
    "for i in range(1,161):\n",
    "    loss_1.append(float(lines[i][-39:-33]))\n",
    "    loss_2.append(float(lines[i][-31:-25]))\n",
    "    loss_3.append(float(lines[i][-23:-17]))\n",
    "    loss_4.append(float(lines[i][-15:-9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f882abc6e04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig_lc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m fig_lc.suptitle('Learning curves \\nNumber of trainable parameters: {}, \\nFinal loss 1: {:.3f} , loss 2: {:.3f} , loss 3: {:.3f}, loss 4: {:.3f}'.format(\n\u001b[0;32m----> 5\u001b[0;31m                    300409, np.mean(loss_1[-2:]), np.mean(loss_2[-2:]),  np.mean(loss_3[-2:]),np.mean(loss_4[-2:]) ), fontsize=14)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#plt.figure(figsize = (8,8))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3118\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = '/home/riccardo/Desktop/Experiments/decoder_sup/3_digts/arch/BL'\n",
    "\n",
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Learning curves \\nNumber of trainable parameters: {}, \\nFinal loss 1: {:.3f} , loss 2: {:.3f} , loss 3: {:.3f}, loss 4: {:.3f}'.format(\n",
    "                   300409, np.mean(loss_1[-2:]), np.mean(loss_2[-2:]),  np.mean(loss_3[-2:]),np.mean(loss_4[-2:]) ), fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(data['iter'], loss_1, 'coral', linewidth=2.5, label = \"train reconstruction loss\")\n",
    "plt.plot(data['iter'], loss_2, 'dodgerblue', linewidth=2, label = \"gnrl reconstruction loss\")\n",
    "plt.plot(data['iter'], loss_3, 'seagreen', linewidth=2, label = \"gnrl reconstruction loss\")\n",
    "plt.plot(data['iter'], loss_4, 'r', linewidth=2, label = \"gnrl reconstruction loss\")\n",
    "\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "#plt.title(\"losses\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/Train_Recurrent_loss_Curves.png'.format(output_dir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
