{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "import sys\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/home/riccardo/Desktop/OcclusionInference/Architectures')\n",
    "\n",
    "from models.BLT_models import multi_VAE\n",
    "from data_loaders.dataset_sup import MyDataset_encoder, MyDataset_decoder\n",
    "from data_loaders.dataset_unsup import MyDataset_unsup\n",
    "\n",
    "from models.Lin_model import Lin_model \n",
    "\n",
    "from solvers.utils_mod import DataGather, get_accuracy\n",
    "from solvers.losses import supervised_encoder_loss\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using BLT encoder BLT decoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_1 = multi_VAE('BLT','BLT', 12, 0 ,32, 1, 4, False, 4, 1, False)\n",
    "file_path = '/home/riccardo/Desktop/Experiments/AE/Unfrozen/2_digts/BLT_BLT_depth_zdim12_2/main/last'\n",
    "checkpoint = torch.load(file_path) \n",
    "net_1.load_state_dict(checkpoint['model_states']['net'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def traverse_z(NN, example_id, ID, output_dir, global_iter, sbd ,num_frames = 100 ):\n",
    "    z_dim = NN.z_dim_tot\n",
    "    \n",
    "    x_test_sample = example_id['x']\n",
    "    y_test_sample = example_id['y']\n",
    "    x_test_sample = torch.unsqueeze(x_test_sample, 0)\n",
    "    \n",
    "    #encode a sample image\n",
    "    z_distributions = NN._encode(x_test_sample)\n",
    "    z_distributions = z_distributions[-1]\n",
    "    z_sample = z_distributions[:, :NN.z_dim_bern]\n",
    "   \n",
    "    num_slice = int(1000/num_frames)\n",
    "\n",
    "\n",
    "    dist_samples = np.random.uniform(low=-6, high=6, size=1000)\n",
    "    dist_samples.sort()\n",
    "    dist_samples = torch.from_numpy(dist_samples[0::num_slice])\n",
    "\n",
    "            \n",
    "    traverse_input = torch.mul(torch.ones(num_frames*z_dim,1),z_sample)\n",
    "    \n",
    "     \n",
    "    #print(traverse_input.shape)\n",
    "\n",
    "    indexs = np.arange(0, num_frames*z_dim, num_frames)\n",
    "    for i in indexs:\n",
    "        z = int(i/num_frames)\n",
    "        traverse_input[i:(i+num_frames),z] = dist_samples\n",
    "   \n",
    "    #create all reconstruction images\n",
    "    x_recon = NN._decode(z_sample)\n",
    "    x_recon = x_recon[-1]\n",
    "    reconst = NN._decode(traverse_input)\n",
    "    reconst = reconst[-1]\n",
    "    print(reconst.shape)\n",
    "\n",
    "    #Create GIFs\n",
    "    indexs = np.arange(0, num_frames*z_dim, num_frames)\n",
    "    for i in indexs:\n",
    "        #save images for each gif into the images list\n",
    "        images = []\n",
    "        for e in range(num_frames):\n",
    "            #save images to make gifs into different folders\n",
    "            filename = '{}/traversals{}_{}/z{}/img{}.png'.format(output_dir,global_iter,ID,int(i/num_frames),e)\n",
    "            directory = os.path.dirname(filename)\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torchvision.utils.save_image(F.sigmoid(reconst[i+e,0,:,:].cpu()) , filename)\n",
    "            images.append(imageio.imread(filename))\n",
    "\n",
    "\n",
    "        #save all gifs into same folder\n",
    "        filename_2 = '{}/traversals_gifs{}_{}/traversing_z_{}.gif'.format(\n",
    "            output_dir,global_iter, ID,int(i/num_frames),int(i/num_frames))\n",
    "        directory_2 = os.path.dirname(filename_2)\n",
    "        if not os.path.exists(directory_2):\n",
    "                os.makedirs(directory_2)\n",
    "        imageio.mimsave('{}/traversals_gifs{}_{}/traversing_z_{}.gif'.format(\n",
    "            output_dir, global_iter, ID, int(i/num_frames),int(i/num_frames)), images)\n",
    "        \n",
    "        with open('{}/traversals_gifs{}_{}/encoded_z.txt'.format(output_dir,global_iter,ID), 'w') as f:\n",
    "            f.write(str(z_sample.detach().numpy()))\n",
    "        \n",
    "        #add the reconstruction image to the GIF image folder\n",
    "        torchvision.utils.save_image(F.sigmoid(x_recon[0,0,:,:]),\n",
    "                                        '{}/traversals_gifs{}_{}/recon.png'.format(output_dir,global_iter,ID))\n",
    "        #add the actual target image to the GIF image folder\n",
    "        torchvision.utils.save_image(y_test_sample[0,:,:],\n",
    "                                        '{}/traversals_gifs{}_{}/target.png'.format(output_dir,global_iter,ID))\n",
    "        shutil.rmtree(directory)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting gnrl image files\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/train/orig/\"\n",
    "train_target_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/digts.csv\"\n",
    "\n",
    "gnrl_image_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/gnrl/orig/\"\n",
    "gnrl_target_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/gnrl/inverse/\"\n",
    "\n",
    "dset = MyDataset_unsup\n",
    "train_data_size = len(os.listdir(train_image_paths))\n",
    "\n",
    "encoder_target_type = 'depth_ordered_one_hot_xy'\n",
    "\n",
    "gnrl_data = dset(gnrl_image_paths,gnrl_target_paths, 32, 'gnrl',train_data_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 1, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riccardo/miniconda3/envs/rconci/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1200, 1, 32, 32])\n",
      "torch.Size([1200, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/home/riccardo/Desktop/Experiments/traverse_AE/border2'\n",
    "\n",
    "for i in range(3):\n",
    "    example_id = gnrl_data.__getitem__(i)\n",
    "    traverse_z(net_1,example_id,  ID=str(i),output_dir=output_dir,global_iter=100000,  sbd = False, num_frames=100  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
