{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/home/riccardo/Desktop/OcclusionInference/Architectures')\n",
    "\n",
    "from models.BLT_models import multi_VAE\n",
    "from data_loaders.dataset_sup import MyDataset_encoder, MyDataset_decoder\n",
    "from models.Lin_model import Lin_model \n",
    "\n",
    "from solvers.utils_mod import DataGather, get_accuracy\n",
    "from solvers.losses import supervised_encoder_loss\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lin_model(\n",
      "  (layer1): Linear(in_features=36, out_features=36, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "test = Lin_model(36,36)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting train image files\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/train/orig/\"\n",
    "train_target_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/digts.csv\"\n",
    "gnrl_image_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/gnrl/orig/\"\n",
    "gnrl_target_paths = \"/home/riccardo/Desktop/Data/100k_2digt_BWE_2/digts/digts_gnrl.csv\"\n",
    "\n",
    "dset = MyDataset_encoder\n",
    "train_data_size = len(os.listdir(train_image_paths))\n",
    "\n",
    "encoder_target_type = 'depth_ordered_one_hot_xy'\n",
    "\n",
    "train_data = dset(train_image_paths,train_target_paths, 32, encoder_target_type, 'train',train_data_size )\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                            batch_size=100,\n",
    "                            shuffle=False,\n",
    "                            num_workers=8,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False)\n",
    "\n",
    "# gnrl_data = dset(gnrl_image_paths,gnrl_target_paths, 32, encoder_target_type, 'gnrl',train_data_size )\n",
    "# gnrl_loader = DataLoader(gnrl_data,\n",
    "#                             batch_size=100,\n",
    "#                             shuffle=False,\n",
    "#                             num_workers=8,\n",
    "#                             pin_memory=True,\n",
    "#                             drop_last=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using BLT encoder BLT decoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_1 = multi_VAE('BLT','BLT', 24, 0 ,32, 1, 4, False, 4, 1, False)\n",
    "file_path = '/home/riccardo/Desktop/Experiments/AE/Unfrozen/2_digts/BLT_BLT_depth_zdim24_2/main/last'\n",
    "checkpoint = torch.load(file_path) \n",
    "net_1.load_state_dict(checkpoint['model_states']['net'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_digits = 2\n",
    "\n",
    "z_code = 24\n",
    "lr = 1e-3\n",
    "beta1= 0.9\n",
    "beta2= 0.999\n",
    "max_epoch = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lin_model(\n",
      "  (layer1): Linear(in_features=24, out_features=24, bias=True)\n",
      ")\n",
      "1000 iters per epoch\n",
      "0\n",
      "[0] train loss:155.390\n",
      "[0] back loss:9.547, mid loss:0.000, front loss:7.843, xy_loss:138.000\n",
      "[0], train_back_accuracy:6.000, train_front_accuracy:16.000\n",
      "[250] train loss:35.041\n",
      "[250] back loss:4.569, mid loss:0.000, front loss:4.362, xy_loss:26.109\n",
      "500\n",
      "[500] train loss:11.051\n",
      "[500] back loss:3.003, mid loss:0.000, front loss:2.822, xy_loss:5.226\n",
      "[500], train_back_accuracy:12.000, train_front_accuracy:16.000\n",
      "[750] train loss:6.096\n",
      "[750] back loss:2.586, mid loss:0.000, front loss:2.408, xy_loss:1.102\n",
      "1000\n",
      "[1000] train loss:4.836\n",
      "[1000] back loss:2.237, mid loss:0.000, front loss:2.233, xy_loss:0.366\n",
      "[1000], train_back_accuracy:17.000, train_front_accuracy:15.000\n",
      "[1250] train loss:4.676\n",
      "[1250] back loss:2.247, mid loss:0.000, front loss:2.237, xy_loss:0.192\n",
      "1500\n",
      "[1500] train loss:4.532\n",
      "[1500] back loss:2.191, mid loss:0.000, front loss:2.194, xy_loss:0.146\n",
      "[1500], train_back_accuracy:17.000, train_front_accuracy:17.000\n",
      "[1750] train loss:4.558\n",
      "[1750] back loss:2.222, mid loss:0.000, front loss:2.243, xy_loss:0.093\n",
      "2000\n",
      "[2000] train loss:4.373\n",
      "[2000] back loss:2.118, mid loss:0.000, front loss:2.196, xy_loss:0.059\n",
      "[2000], train_back_accuracy:21.000, train_front_accuracy:23.000\n",
      "[2250] train loss:4.435\n",
      "[2250] back loss:2.156, mid loss:0.000, front loss:2.228, xy_loss:0.051\n",
      "2500\n",
      "[2500] train loss:4.402\n",
      "[2500] back loss:2.152, mid loss:0.000, front loss:2.201, xy_loss:0.049\n",
      "[2500], train_back_accuracy:13.000, train_front_accuracy:19.000\n",
      "[2750] train loss:4.465\n",
      "[2750] back loss:2.192, mid loss:0.000, front loss:2.241, xy_loss:0.032\n",
      "3000\n",
      "[3000] train loss:4.324\n",
      "[3000] back loss:2.102, mid loss:0.000, front loss:2.195, xy_loss:0.027\n",
      "[3000], train_back_accuracy:21.000, train_front_accuracy:22.000\n",
      "[3250] train loss:4.393\n",
      "[3250] back loss:2.140, mid loss:0.000, front loss:2.229, xy_loss:0.024\n",
      "3500\n",
      "[3500] train loss:4.379\n",
      "[3500] back loss:2.149, mid loss:0.000, front loss:2.206, xy_loss:0.024\n",
      "[3500], train_back_accuracy:18.000, train_front_accuracy:18.000\n",
      "[3750] train loss:4.445\n",
      "[3750] back loss:2.182, mid loss:0.000, front loss:2.243, xy_loss:0.020\n",
      "4000\n",
      "[4000] train loss:4.311\n",
      "[4000] back loss:2.096, mid loss:0.000, front loss:2.195, xy_loss:0.020\n",
      "[4000], train_back_accuracy:20.000, train_front_accuracy:22.000\n",
      "[4250] train loss:4.383\n",
      "[4250] back loss:2.136, mid loss:0.000, front loss:2.229, xy_loss:0.019\n",
      "4500\n",
      "[4500] train loss:4.377\n",
      "[4500] back loss:2.149, mid loss:0.000, front loss:2.210, xy_loss:0.018\n",
      "[4500], train_back_accuracy:19.000, train_front_accuracy:17.000\n",
      "[4750] train loss:4.439\n",
      "[4750] back loss:2.177, mid loss:0.000, front loss:2.244, xy_loss:0.018\n",
      "5000\n",
      "[5000] train loss:4.307\n",
      "[5000] back loss:2.094, mid loss:0.000, front loss:2.195, xy_loss:0.019\n",
      "[5000], train_back_accuracy:18.000, train_front_accuracy:22.000\n",
      "[5250] train loss:4.381\n",
      "[5250] back loss:2.134, mid loss:0.000, front loss:2.229, xy_loss:0.018\n",
      "5500\n",
      "[5500] train loss:4.378\n",
      "[5500] back loss:2.149, mid loss:0.000, front loss:2.212, xy_loss:0.017\n",
      "[5500], train_back_accuracy:20.000, train_front_accuracy:15.000\n",
      "[5750] train loss:4.437\n",
      "[5750] back loss:2.175, mid loss:0.000, front loss:2.244, xy_loss:0.018\n",
      "6000\n",
      "[6000] train loss:4.305\n",
      "[6000] back loss:2.092, mid loss:0.000, front loss:2.194, xy_loss:0.019\n",
      "[6000], train_back_accuracy:20.000, train_front_accuracy:23.000\n",
      "[6250] train loss:4.380\n",
      "[6250] back loss:2.133, mid loss:0.000, front loss:2.229, xy_loss:0.017\n",
      "6500\n",
      "[6500] train loss:4.380\n",
      "[6500] back loss:2.149, mid loss:0.000, front loss:2.213, xy_loss:0.018\n",
      "[6500], train_back_accuracy:20.000, train_front_accuracy:14.000\n",
      "[6750] train loss:4.436\n",
      "[6750] back loss:2.173, mid loss:0.000, front loss:2.244, xy_loss:0.019\n",
      "7000\n",
      "[7000] train loss:4.304\n",
      "[7000] back loss:2.092, mid loss:0.000, front loss:2.194, xy_loss:0.019\n",
      "[7000], train_back_accuracy:20.000, train_front_accuracy:23.000\n",
      "[7250] train loss:4.380\n",
      "[7250] back loss:2.133, mid loss:0.000, front loss:2.230, xy_loss:0.018\n",
      "7500\n",
      "[7500] train loss:4.381\n",
      "[7500] back loss:2.149, mid loss:0.000, front loss:2.214, xy_loss:0.018\n",
      "[7500], train_back_accuracy:20.000, train_front_accuracy:14.000\n",
      "[7750] train loss:4.436\n",
      "[7750] back loss:2.173, mid loss:0.000, front loss:2.244, xy_loss:0.019\n",
      "8000\n",
      "[8000] train loss:4.304\n",
      "[8000] back loss:2.091, mid loss:0.000, front loss:2.194, xy_loss:0.019\n",
      "[8000], train_back_accuracy:20.000, train_front_accuracy:23.000\n",
      "[8250] train loss:4.380\n",
      "[8250] back loss:2.133, mid loss:0.000, front loss:2.230, xy_loss:0.018\n",
      "8500\n",
      "[8500] train loss:4.381\n",
      "[8500] back loss:2.149, mid loss:0.000, front loss:2.214, xy_loss:0.018\n",
      "[8500], train_back_accuracy:20.000, train_front_accuracy:14.000\n",
      "[8750] train loss:4.435\n",
      "[8750] back loss:2.172, mid loss:0.000, front loss:2.244, xy_loss:0.019\n",
      "9000\n",
      "[9000] train loss:4.304\n",
      "[9000] back loss:2.091, mid loss:0.000, front loss:2.194, xy_loss:0.019\n",
      "[9000], train_back_accuracy:20.000, train_front_accuracy:23.000\n",
      "[9250] train loss:4.380\n",
      "[9250] back loss:2.132, mid loss:0.000, front loss:2.230, xy_loss:0.018\n",
      "9500\n",
      "[9500] train loss:4.382\n",
      "[9500] back loss:2.149, mid loss:0.000, front loss:2.215, xy_loss:0.018\n",
      "[9500], train_back_accuracy:20.000, train_front_accuracy:15.000\n",
      "[9750] train loss:4.435\n",
      "[9750] back loss:2.172, mid loss:0.000, front loss:2.244, xy_loss:0.019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if encoder_target_type == 'joint':\n",
    "    z_out = 10\n",
    "elif encoder_target_type == 'black_white':\n",
    "    z_out = 20\n",
    "elif encoder_target_type == 'depth_black_white':\n",
    "    z_out = 21\n",
    "elif encoder_target_type == 'depth_black_white_xy_xy':\n",
    "    z_out = 25\n",
    "elif encoder_target_type== \"depth_ordered_one_hot\":\n",
    "    if n_digits == 2:\n",
    "        z_out = 20\n",
    "    elif self.n_digits ==3:\n",
    "        z_out = 30\n",
    "elif encoder_target_type== \"depth_ordered_one_hot_xy\":\n",
    "    if n_digits == 2:\n",
    "        z_out = 24\n",
    "    elif n_digits ==3:\n",
    "        z_out = 36\n",
    "    \n",
    "lin_net = Lin_model(z_code, z_out)\n",
    "optim_2 = optim.Adam(lin_net.parameters(), lr=lr, betas=(beta1, beta2))    \n",
    "\n",
    "if torch.cuda.device_count()>1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    lin_net = nn.DataParallel(lin_net)\n",
    "lin_net = lin_net.to(device) \n",
    "print(lin_net)\n",
    "\n",
    "iters_per_epoch = len(train_loader)\n",
    "print(iters_per_epoch, 'iters per epoch')\n",
    "max_iter = max_epoch*iters_per_epoch\n",
    "batch_size = train_loader.batch_size\n",
    "\n",
    "count = 0\n",
    "out = False\n",
    "\n",
    "count_list = []\n",
    "Tot_loss_list = []\n",
    "back_loss_list = []\n",
    "mid_loss_list = []\n",
    "front_loss_list = []\n",
    "xy_loss_list = []\n",
    "back_accuracy_list = []\n",
    "mid_accuracy_list = []\n",
    "front_accuracy_list = []\n",
    "\n",
    "while not out:\n",
    "    for sample in train_loader:\n",
    "        if count%500==0:\n",
    "            print(count)\n",
    "\n",
    "        x = sample['x'].to(device)\n",
    "        y = sample['y'].to(device)\n",
    "    \n",
    "        net_1 = net_1.to(device)\n",
    "        with torch.no_grad():\n",
    "            output_list = net_1._encode(x)\n",
    "            \n",
    "            output = output_list[-1]\n",
    "            output = output[:, :z_out]\n",
    "        \n",
    "        final_out = lin_net(output)\n",
    "        \n",
    "  \n",
    "        loss_list = supervised_encoder_loss(final_out, y, n_digits, encoder_target_type)\n",
    "        loss = loss_list[0]\n",
    "        \n",
    "#         l2 = 0\n",
    "#         for p in lin_net.parameters():\n",
    "#             l2 = l2 + p.pow(2).sum() #*0.5\n",
    "#         loss = loss + net.l2_loss * l2\n",
    "\n",
    "        optim_2.zero_grad()\n",
    "        loss.backward()\n",
    "        optim_2.step()\n",
    "        \n",
    "        if count%250==0:\n",
    "            print('[{}] train loss:{:.3f}'.format(count, loss.item()))\n",
    "            print('[{}] back loss:{:.3f}, mid loss:{:.3f}, front loss:{:.3f}, xy_loss:{:.3f}'.format(count, loss_list[1].item(), loss_list[2].item(), loss_list[3].item(), loss_list[4].item()))\n",
    "\n",
    "\n",
    "        if count%500==0:\n",
    "            if encoder_target_type== 'joint':\n",
    "                train_accuracy = get_accuracy(final_out, y, encoder_target_type, n_digits)\n",
    "            elif encoder_target_type== \"depth_black_white\" or encoder_target_type== \"depth_black_white_xy_xy\":\n",
    "                accuracy_list = get_accuracy(final_out,y,encoder_target_type, n_digits)\n",
    "                train_depth_accuracy = accuracy_list[0]\n",
    "                train_black_accuracy = accuracy_list[1]\n",
    "                train_white_accuracy = accuracy_list[2]\n",
    "\n",
    "                print('[{}], train_depth_accuracy:{:.3f}, train_black_accuracy:{:.3f}, train_white_accuracy:{:.3f}'.format(count, train_depth_accuracy, train_black_accuracy, train_white_accuracy))\n",
    "            elif encoder_target_type== \"depth_ordered_one_hot\" or encoder_target_type== \"depth_ordered_one_hot_xy\" :\n",
    "                if n_digits ==2:\n",
    "                    accuracy_list = get_accuracy(final_out,y, encoder_target_type, n_digits)\n",
    "                    train_back_accuracy = accuracy_list[0]\n",
    "                    train_front_accuracy = accuracy_list[1]\n",
    "                    \n",
    "                    edit_loss_list = [x.item() for x in loss_list]\n",
    "                    \n",
    "                    count_list.append(count)\n",
    "                    \n",
    "                    Tot_loss_list.append(edit_loss_list[0])\n",
    "                    back_loss_list.append(edit_loss_list[1])\n",
    "                    front_loss_list.append(edit_loss_list[3])\n",
    "                    xy_loss_list.append(edit_loss_list[4])\n",
    "                    \n",
    "                    back_accuracy_list.append(train_back_accuracy.item())\n",
    "                    front_accuracy_list.append(train_front_accuracy.item())\n",
    "                    \n",
    "                    print('[{}], train_back_accuracy:{:.3f}, train_front_accuracy:{:.3f}'.format(count, train_back_accuracy, train_front_accuracy))\n",
    "\n",
    "                elif n_digits ==3:\n",
    "                    accuracy_list = get_accuracy(final_out,y, encoder_target_type , n_digits)\n",
    "                    train_back_accuracy = accuracy_list[0]\n",
    "                    train_mid_accuracy = accuracy_list[1]\n",
    "                    train_front_accuracy = accuracy_list[2]\n",
    "                    \n",
    "                    \n",
    "                    edit_loss_list = [x.item() for x in loss_list]\n",
    "                    \n",
    "                    count_list.append(count)\n",
    "                    \n",
    "                    Tot_loss_list.append(edit_loss_list[0])\n",
    "                    back_loss_list.append(edit_loss_list[1])\n",
    "                    mid_loss_list.append(edit_loss_list[2])\n",
    "                    front_loss_list.append(edit_loss_list[3])\n",
    "                    xy_loss_list.append(edit_loss_list[4])\n",
    "                    \n",
    "                    back_accuracy_list.append(train_back_accuracy.item())\n",
    "                    mid_accuracy_list.append(train_mid_accuracy.item())\n",
    "                    front_accuracy_list.append(train_front_accuracy.item())\n",
    "\n",
    "                    print('[{}], train_back_accuracy:{:.3f}, train_mid_accuracy:{:.3f}, train_front_accuracy:{:.3f}'.format(count, train_back_accuracy, train_mid_accuracy, train_front_accuracy))\n",
    "\n",
    "        count +=1 \n",
    "        if count >= max_iter:\n",
    "            out = True\n",
    "            break\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "count_list = []\n",
    "Tot_loss_list = []\n",
    "back_loss_list = []\n",
    "mid_loss_list = []\n",
    "front_loss_list = []\n",
    "xy_loss_list  = []\n",
    "back_accuracy_list = []\n",
    "mid_accuracy_list = []\n",
    "front_accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-88a42bf295b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m fig_lc.suptitle('Linear Decoder Training \\n Min Losses: back: {:.2f}, mid:{:.2f}, front:{:.2f}, xy:{:.2f} '.format(\n\u001b[1;32m      5\u001b[0m                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid_loss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfront_loss_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     np.min(xy_loss_list) ), fontsize=14)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \"\"\"\n\u001b[1;32m   2617\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2618\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rconci/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = '/home/riccardo/Desktop/Experiments/LinDecoder/border2/'\n",
    "\n",
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Linear Decoder Training \\n Min Losses: back: {:.2f}, mid:{:.2f}, front:{:.2f}, xy:{:.2f} '.format(\n",
    "                   np.min(back_loss_list),\n",
    "                   np.min(mid_loss_list), np.min(front_loss_list) , \n",
    "                    np.min(xy_loss_list) ), fontsize=14)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(count_list, back_loss_list, 'coral', linewidth=2.5, label = \"back digit loss\")\n",
    "plt.plot(count_list, mid_loss_list, 'seagreen', linewidth=2.5, label = \"mid digit loss\")\n",
    "plt.plot(count_list, front_loss_list, 'dodgerblue', linewidth=2.5, label = \"front digit loss\")\n",
    "plt.plot(count_list, xy_loss_list, 'r', linewidth=2.5, label = \"location loss\")\n",
    "plt.xlabel(\"iterations\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "#plt.title(\"losses\")\n",
    "plt.legend(fontsize=15)\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/LinDecoder_loss_Curves.png'.format(output_dir))\n",
    "plt.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_lc = plt.figure(figsize = (8,8))\n",
    "fig_lc.suptitle('Linear Decoder Training \\n Max accuracy: back: {:.2f}, mid:{:.2f}, front:{:.2f} '.format(\n",
    "                   np.max(back_accuracy_list),\n",
    "                   np.max(mid_accuracy_list), np.max(front_accuracy_list)),\n",
    "                   fontsize=20)\n",
    "\n",
    "#plt.figure(figsize = (8,8))\n",
    "plt.subplot()\n",
    "plt.plot(count_list, back_accuracy_list, 'coral', linewidth=2.5, label = \"back digit accuracy\")\n",
    "plt.plot(count_list, mid_accuracy_list, 'seagreen', linewidth=2.5, label = \"mid digit accuracy\")\n",
    "plt.plot(count_list, front_accuracy_list, 'dodgerblue', linewidth=2.5, label = \"front digit accuracy\")\n",
    "plt.xlabel(\"iterations\", fontsize=18)\n",
    "plt.ylabel(\"Accuracy\", fontsize=18)\n",
    "#plt.title(\"losses\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.savefig('{}/LinDecoder_accuracy_Curves.png'.format(output_dir))\n",
    "plt.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
